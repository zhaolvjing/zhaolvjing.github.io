---
layout: post
tags: [hive]
toc: true
---

## 运行架构
[官方文档](https://cwiki.apache.org/confluence/display/Hive/Design)

### 核心组件介绍
![](https://zhaolvjing.github.io//image/md/2022-03-25-hive理论-1.hive运行架构.png)

* 用户界面（UI）：包括CLI、JDBC/ODBC、WebGUI。其中，CLI（command line interface）为 shell 命令行；JDBC/ODBC 是 Hive 的 Java 实现，与传统数据库 JDBC 类似；WebGUI 是通过浏览器访问 Hive
* 驱动程序（Driver）：接收查询的组件
* 编译器（Compiler）：负责将 SQL 转化为平台可执行的执行计划。对不同的查询块和查询表达式进行语义分析，并最终借助表和从 MetaStore 查找的分区元数据来生成执行计划
* 元数据库（MetaStore）：存储 Hive 中各种表和分区、字段等的所有结构信息
* 执行引擎（Execution Engine）：负责提交 Compiler 阶段编译好的执行计划到不同的平台上

### Hive Sql 编译过程详解
编译 SQL 的任务是在 Compiler 中完成的，一般有以下几个阶段：

1. 解析器（Sql Parser）：将 SQL 字符串转换成抽象语法树 AST。
2. 语义分析（Semantic Analyser）：遍历 AST Tree，抽象出查询的基本组成单元 QueryBlock。该阶段将验证列名是否正确、分区表达式是否正确等，此外还会执行类型检查和任何隐式类型转换。
3. 逻辑计划生成器（Logical Plan Generator）：遍历 QueryBlock，转换为逻辑执行计划。基本的操作符（OperatorTree）包括：TableScanOperator、SelectOperator、FilterOperator、JoinOperator、GroupByOperator、ReduceSinkOperator 等。此外还会优化逻辑执行计划，如：投影修剪、推导传递谓词、谓词下推、多路 Join等。
4. 物理计划生成器（Query Plan Generator）：生成物理执行计划即是将逻辑执行计划生成的OperatorTree 转化为 MapReduce Job 的过程。此外还会优化物理执行计划，如：
	* 分区修剪(Partition Pruning)；
	* 基于分区和桶的扫描修剪(Scan pruning)；
	* 某些情况下在 map 端应用 Group By；
	* 优化 Union，使 Union 只在 map 端执行；
	* 对于带有 Limit 子句的查询减少需要为该表扫描的文件数；
	* 如果是简单的提取查询，避免使用 MapReduce 作业；
	* 在 map 端 join。

## 内部表和外部表
* 内部表（管理表）：未被关键字 external 修饰的表
* 外部表：被关键字 external 修饰的表
* 二者区别：
	1. 内部表的表数据和元数据都由 Hive 管理；外部表的表数据由 HDFS 管理，元数据由 Hive 管理
	2. 内部表数据存储的位置是 hive.metastore.warehouse.dir（默认：/user/hive/warehouse）；外部表数据存储位置由自己制定
	3. 删除内部表会直接删除元数据及存储数据；删除外部表仅仅会删除元数据，HDFS 上的文件并不会被删除
	4. 对内部表修改时会同步到元数据，而对外部表结构和分区修改时，需要进行修复。sql 语句为：`msck rapair table table_name`

## 分区和分桶
### 分区
* 概念：分区表提供了一种隔离数据和优化查询的便利方式，从形式上可以理解为文件夹。常用的分区字段如时间等。
* 使用场景：庞大的数据集一次读取需要耗费大量的时间去处理。在许多场景下，可以通过分区或切片的方法减少每一次扫描总数据量，这种做法可以显著地改善查询性能。

### 分桶
* 概念：分桶是相对分区进行更细粒度的划分。针对指定列进行哈希（hash）计算，然后会根据 hash 值进行切分数据，将具有不同 hash 值的数据写到每个桶对应的文件中，从形式上可以理解为文件。
* 使用场景：数据抽样

